---
title: Apply other steps and models from recipes and parsnip packages
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Apply other steps and models from recipes and parsnip packages}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---
The `epipredict` package utilizes the `tidymodels` framework, namely 
[`recipes`](https://recipes.tidymodels.org/) for 
[dplyr](https://dplyr.tidyverse.org/)-like pipeable sequences 
of feature engineering and [`parsnip`](https://parsnip.tidymodels.org/) for a 
unified interface to a range of models. 

`epipredict` has additional customized feature engineering and preprocessing steps 
tailored to fit the needs of epidemiology forecasting, such as `step_epi_shift()`, 
`step_population_scaling()`, `step_epi_naomit()`. They can be used along with 
steps from the `recipes` package for more feature engineering. 

In this vignette, we will demonstrate how to weave `recipes` steps and `parsnip`
models into the `epipredict` workflow. 

First, let's load the necessary packages:

```{r, warning=FALSE, message =FALSE}
library(epipredict)
library(epiprocess)
library(recipes)
library(parsnip)
library(workflows)
library(poissonreg)
```

We will use the built-in dataset `case_death_rate_subset` and apply feature 
engineering steps and fit a few models from `parsnip` to predict future death 
rates by states 7 days ahead from Dec 31, 2021.

```{r}
x <- case_death_rate_subset
x$geo_value <- as.factor(x$geo_value)
tail(x)
```
There are `r dim(x)[1]` rows and `r dim(x)[2]` columns in the data, with dates
ranging from `r min(x$time_value)` to `r max(x$time_value)` in 
`r n_distinct(x$geo_value)` states in the U.S.

# Preprocessing and Feature Engineering

In this section, we focus on showing how `step_*()` functions from the `recipes`
package can also be applied in our `epipredict` workflows. 

First, create a recipe object from the original data and then specify the 
preprocessing steps. Steps are then sequentially added.

```{r create-recipe-object}
r <- epi_recipe(x)
r
```

The function automatically categorizes roles into `geo_value`, `time_value` and 
`raw` based on variable names, where `raw` includes `case_rate` and `death_rate`. 

We first create a made-up population dataset by states to allow the conversion
from `case_rate` and `death_rate` into `cases` and  `deaths`. The binary variable
`social_distancing` indicates whether the state followed social distancing rules.
A 'throw-away' column with all ones is also created to show that `step_rm()` 
can be used to remove unwanted columns.
```{r madeup-population-data}
pop_data <- data.frame(states = unique(x$geo_value),
                       inv_pop = 1/seq(1e5, 1e7, 
                                       length.out = n_distinct(x$geo_value)),
                       social_distancing = rbinom(n = n_distinct(x$geo_value), 
                                                  size = 1,
                                                  prob = 0.5),
                       throw_away = 1)

head(pop_data)
```

Next, we will feature engineer `case_rate` and `death_rate` into `cases` and 
`deaths`and create lags and leads based on them. 

```{r create-new-columns-in-recipe}
r <- r %>%
  step_population_scaling(case_rate, death_rate, df = pop_data, 
                          by = c("geo_value" = "states"),
                          create_new = FALSE,
                          df_pop_col = "inv_pop") %>%
  step_rename(cases = case_rate, deaths = death_rate) %>%
  step_rm(throw_away) %>%
  step_epi_lag(cases, lag = c(0, 7, 14), role = "predictor") %>%
  step_epi_lag(deaths, lag = c(0, 7, 14), role = "predictor") %>%
  step_epi_ahead(deaths, ahead = 7, role = "outcome") %>%
  step_epi_naomit() %>%
  step_rm(cases, deaths)

```

Notice that `step_rename()` was used for renaming of the variables, and 
`step_rm()` was used to remove redundant columns.

A quick view of what columns exist in the the prepossessed data so far:

```{r peak-data-1}
names(bake(prep(r, x),x))
```

There are also many functions in the `recipes` package that allow for 
[function transformations](https://recipes.tidymodels.org/reference/#step-functions-individual-transformations),
such as log transformations and spline transformations. In our case, we will 
center the numerical predictors to allow for meaningful interpretation of the 
intercept. 

```{r}
r <- r %>% step_center(contains("lag"))
```

Since the current outcomes are positive, but the linear regression assumes the 
outcome to be in full support, we will consider a log-transformation.

```{r}
r_lin <- r %>% step_log(ahead_7_deaths, role = "outcome")
```

Other useful functionalities include creating a set of binary dummy variables 
from a factor variable. As an illustration that will not affect the models, we 
will show how states in `geo_value` become dummy variables so that each state 
as a dummy variable has a differential intercept coefficient.

```{r dummy-variable}
length(unique(x$geo_value))

dummies <- r %>% 
  step_dummy(geo_value) %>%
  prep(training = x) 

dummy_data <- bake(dummies, x)

names(dummy_data)
```

Once the pre-processing steps are done, we can move on to model fitting using 
the `parsnip` package. 


# Model Fitting and Post-processing

Sometimes, the exact values are desired, therefore fitting a linear regression 
or poisson regression would be a good idea. 

On the other hand, say instead of predicting 7-day ahead death counts, we would 
like to classify if the future predictions are high or low based on some given threshold. 
In this case, a logistic regression among other classification models can be used.
For the purpose of illustration, we define two categories: less than 10K(low) 
and more than 10K(high). 

We resort to the `recipes` package again to change the numerical outcomes to 
categorical for the purpose of classification:

```{r, warning = FALSE}
binner <- function(x) {
  x <- cut(x, breaks = c(0, 10000, Inf), include.lowest = TRUE)
  # now return the group number
  as.numeric(x)
}

inc <- c("low", "high")

r_categorical <- r %>% 
  step_num2factor(ahead_7_deaths, 
                  role = "outcome", 
                  transform = binner, 
                  levels = inc)

```

As a sanity check we can see now that the preprocessed data has a categorical 
outcome in `ahead_7_deaths`. 

```{r, warning FALSE, echo = FALSE}
glimpse(slice_sample(bake(prep(r_categorical, x),x), n = 6))
```


### Linear Regression

First, we can try fitting a linear regression:

```{r linear-fit-workflow, warning = FALSE}
wf <- epi_workflow(r_lin, parsnip::linear_reg()) %>%
    fit(x) 

latest <- get_test_data(recipe = r_lin, x = x)
```

We take a look at the linear regression fit and the values of the coefficients.

```{r linear-fit, warning = FALSE}
wf$fit$fit # look at the model fit and coefficients

p <- predict(wf, latest) %>% filter(!is.na(.pred))

p
```

The predictions are saved in the `.pred` column and represents the log-transformed 
predicted death counts 7 days from Dec 31. 2021. 


### Poisson regression

For count data, we can use poisson regression. Although the counts here are not 
integer since they were calculated from case rates multiplying population, some 
extra preprocessing steps can help us round them to integers to allow fitting a 
poisson regression.


```{r poisson-fit}
r <- r %>% step_mutate(ahead_7_deaths = round(ahead_7_deaths, 0), 
                       role = "predictor") %>%
  step_filter(ahead_7_deaths > 0)

latest <- get_test_data(recipe = r, x = x)

wf <- epi_workflow(r, parsnip::poisson_reg()) %>%
    fit(x) %>%
    add_frosting(f)

predict(wf, latest) %>% select( - social_distancing, - throw_away)
```

Let's also take a look at the poisson regression fit:
```{r, echo =FALSE}
wf$fit$fit
```

### Logistic Regression

We use a logistic regression to predict whether 7-day ahead death counts are high
or low. Post-processing steps do not need to be applied here. 
```{r logistic, warning = FALSE}
wf <- epi_workflow(r_categorical, parsnip::logistic_reg()) %>%
    fit(x) 
latest <- get_test_data(recipe = r_categorical, x = x)
p <- predict(wf, latest) %>% filter(!is.na(.pred_class))
p
```

The model fit is as follows:
```{r echo=FALSE}
wf$fit$fit
```

# Attribution

This object contains a modified part of the [COVID-19 Data Repository by the Center for Systems Science and Engineering (CSSE) at Johns Hopkins University](https://github.com/CSSEGISandData/COVID-19) as [republished in the COVIDcast Epidata API.](https://cmu-delphi.github.io/delphi-epidata/api/covidcast-signals/jhu-csse.html)

This data set is licensed under the terms of the [Creative Commons Attribution 4.0 International license](https://creativecommons.org/licenses/by/4.0/) by the Johns Hopkins University 
on behalf of its Center for Systems Science in Engineering. Copyright Johns Hopkins University 2020.

