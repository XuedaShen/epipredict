---
title: Apply other steps and models from recipes and parsnip packages
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Apply other steps and models from recipes and parsnip packages}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---
The `epipredict` package utilizes the `tidymodels` framework, namely 
[`recipes`](https://recipes.tidymodels.org/) for 
[dplyr](https://dplyr.tidyverse.org/)-like pipeable sequences 
of feature engineering and [`parsnip`](https://parsnip.tidymodels.org/) for a 
unified interface to a range of models. 

`epipredict` has additional customized feature engineering and preprocessing steps 
tailored to fit the needs of epidemiology forecasting, such as `step_epi_shift()`, 
`step_population_scaling()`, `step_epi_naomit()`. They can be used along with 
steps from the `recipes` package for more feature engineering. 

In this vignette, we will demonstrate how to weave `recipes` steps and `parsnip`
models into the `epipredict` workflow. 

First, let's load the necessary packages:

```{r, warning=FALSE, message =FALSE}
library(epipredict)
library(epiprocess)
library(recipes)
library(parsnip)
library(workflows)
library(poissonreg)
```

We will use the built-in dataset `case_death_rate_subset` and apply feature 
engineering steps and fit a few models from `parsnip` to predict future death 
rates by states 7 days ahead from Dec 31, 2021.

```{r}
x <- case_death_rate_subset
tail(x)
```
There are `r dim(x)[1]` rows and `r dim(x)[2]` columns in the data, with dates
ranging from `r min(x$time_value)` to `r max(x$time_value)` in 
`r n_distinct(x$geo_value)` states in the U.S.

# Preprocessing and Feature Engineering

In this section, we focus on showing how `step_*()` functions from the `recipes`
package can also be applied in our `epipredict` workflows. 

First, create a recipe object from the original data and then specify the 
preprocessing steps. Steps are then sequentially added.

```{r create-recipe-object}
r <- epi_recipe(x)
r
```

The function automatically categorizes roles into `geo_value`, `time_value` and 
`raw` based on variable names, where `raw` includes `case_rate` and `death_rate`. 

We first create a made-up population dataset by states to allow the conversion
from `case_rate` and `death_rate` into `cases` and  `deaths`. The binary variable
`social_distancing` indicates whether the state followed social distancing rules.
A 'throw-away' column with all ones is also created to show that `step_rm()` 
can be used to remove unwanted columns.
```{r madeup-population-data}
pop_data <- data.frame(states = unique(x$geo_value),
                       inv_pop = 1/seq(1e5, 1e7, 
                                       length.out = n_distinct(x$geo_value)),
                       social_distancing = rbinom(n = n_distinct(x$geo_value), 
                                                  size = 1,
                                                  prob = 0.5),
                       throw_away = 1)

head(pop_data)
```

Next, we will feature engineer `case_rate` and `death_rate` into `cases` and 
`deaths`and create lags and leads based on them. 

```{r create-new-columns-in-recipe}
r <- r %>%
  step_population_scaling(case_rate, death_rate, df = pop_data, 
                          by = c("geo_value" = "states"),
                          create_new = FALSE,
                          df_pop_col = "inv_pop") %>%
  step_rename(cases = case_rate, deaths = death_rate) %>%
  step_rm(throw_away) %>%
  step_epi_lag(cases, lag = c(0, 7, 14), role = "predictor") %>%
  step_epi_lag(deaths, lag = c(0, 7, 14), role = "predictor") %>%
  step_epi_ahead(deaths, ahead = 7, role = "outcome") %>%
  step_epi_naomit() %>%
  step_rm(cases, deaths)

```

Notice that `step_rename()` was used for renaming of the variables, and 
`step_rm()` was used to remove redundant columns.

A quick view of what columns exist in the the prepossessed data so far:

```{r peak-data-1}
names(bake(prep(r, x),x))
```

There are also many functions in the `recipes` package that allow for 
[function transformations](https://recipes.tidymodels.org/reference/#step-functions-individual-transformations),
such as log transformations and spline transformations. 

Sometimes, the exact counts are desired, therefore fitting a linear regression 
or poisson regression would be a good idea. 

On the other hand, say instead of predicting 7-day ahead death counts, we would 
like to predict if the counts are high or low based on some given threshold. 
For the purpose of illustration, we define two categories: less than 10K(low) 
and more than 10K(high). 

We can resort to the `recipes` package again:

```{r, warning = FALSE}
binner <- function(x) {
  x <- cut(x, breaks = c(0, 10000, Inf), include.lowest = TRUE)
  # now return the group number
  as.numeric(x)
}

inc <- c("low", "high")

r_categorical <- r %>% 
  step_num2factor(ahead_7_deaths, 
                  role = "outcome", 
                  transform = binner, 
                  levels = inc)

```

As a sanity check we can see now that the preprocessed data has a categorical 
outcome in `ahead_7_deaths`
```{r, warning FALSE, echo = FALSE}
glimpse(slice_sample(bake(prep(r_categorical, x),x), n = 6))
```

# Model Fitting and Post-processing

Once the pre-processing steps are done, we can move on to model fitting using 
the `parsnip` package. 

### Linear Regression

First, we can try fitting a linear regression:

```{r linear-fit-workflow, warning = FALSE}
wf <- epi_workflow(r, parsnip::linear_reg()) %>%
    fit(x) 

latest <- get_test_data(recipe = r, x = x)
```

We take a look at the linear regression fit and the values of the coefficients.

```{r linear-fit, warning = FALSE}
wf$fit$fit # look at the model fit and coefficients

p <- predict(wf, latest) %>% filter(!is.na(.pred))

p
```

The predictions are saved in the `.pred` column and represents the squared roots
of predicted death counts 7 days from Dec 31. 2021. 

Some post-processing can be done to revert back to death rates

```{r linear-reg-post-process}
f <- frosting() %>%
    layer_predict() %>%
    layer_threshold(.pred) %>%
    layer_naomit(.pred) %>%
    layer_population_scaling(.pred, df = pop_data,
                             by =  c("geo_value" = "states"),
                             df_pop_col = "inv_pop")

wf <- epi_workflow(r, parsnip::linear_reg()) %>%
    fit(x) %>%
    add_frosting(f)

predict(wf, latest) %>% select( - social_distancing, - throw_away)
```

### Poisson regression

For count data, we can use poisson regression. Although the counts here are not 
integer since they were calculated from case rates multiplying population, some 
extra preprocessing steps can help us round them to integers to allow fitting a 
poisson regression.

We will also apply post-processing steps to the workflow similar to the ones above.

```{r poisson-fit}
r <- r %>% step_mutate(ahead_7_deaths = round(ahead_7_deaths, 0), 
                       role = "predictor") %>%
  step_filter(ahead_7_deaths > 0)

latest <- get_test_data(recipe = r, x = x)

wf <- epi_workflow(r, parsnip::poisson_reg()) %>%
    fit(x) %>%
    add_frosting(f)

predict(wf, latest) %>% select( - social_distancing, - throw_away)
```

Let's also take a look at the poisson regression fit:
```{r, echo =FALSE}
wf$fit$fit
```

### Logistic Regression

We use a logistic regression to predict whether 7-day ahead death counts are high
or low. Post-processing steps do not need to be applied here. 
```{r logistic, warning = FALSE}
wf <- epi_workflow(r_categorical, parsnip::logistic_reg()) %>%
    fit(x) 
latest <- get_test_data(recipe = r_categorical, x = x)
p <- predict(wf, latest) %>% filter(!is.na(.pred_class))
p
```

The model fit is as follows:
```{r echo=FALSE}
wf$fit$fit
```

# Attribution

This object contains a modified part of the [COVID-19 Data Repository by the Center for Systems Science and Engineering (CSSE) at Johns Hopkins University](https://github.com/CSSEGISandData/COVID-19) as [republished in the COVIDcast Epidata API.](https://cmu-delphi.github.io/delphi-epidata/api/covidcast-signals/jhu-csse.html)

This data set is licensed under the terms of the [Creative Commons Attribution 4.0 International license](https://creativecommons.org/licenses/by/4.0/) by the Johns Hopkins University 
on behalf of its Center for Systems Science in Engineering. Copyright Johns Hopkins University 2020.

