---
title: "Demonstrations of sliding AR and ARX forecasters"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Demonstrations of sliding AR and ARX forecasters}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  warning = FALSE,
  message = FALSE
)
```

```{r pkgs}
library(epipredict)
library(epiprocess)
#library(covidcast)
library(data.table)
library(dplyr)
library(tidyr)
library(ggplot2)
```

# Demonstrations of sliding AR and ARX forecasters

An key function from the epiprocess package is `epi_slide()`, which allows the user to apply a function or formula-based computation an `epi_df` over a running window of `n` time steps that may or may not be grouped (see [`epiprocess` "Slide a computation over signal values" vignette](https://cmu-delphi.github.io/epiprocess/articles/advanced.html#version-aware-forecasting-revisited-1) to go over the basics of this function). The equivalent sliding method for an `epi_archive` object can be called by using the wrapper function `epix_slide()` The key difference from `epi_slide()` is that it performs version-aware computations. That is, the function only uses data that would have been available as of time t, for that reference time. 

In this vignette, we demonstrate using `epi_slide()` to slide ARX forecasters over an `epi_df` object and compare the results obtained from using different forecasting engines. We then compare the results from version-aware and unaware forecasting, where former is obtained from applying `epix_slide()` to the `epi_archive` object, while the latter is from applying `epi_slide()` to the latest snapshot of the data.

## Comparing different forecasting engines

### Example using CLI and case data from CA and FL 

First, we download the version history (ie. archive) of the percentage of doctorâ€™s visits with CLI (COVID-like illness) computed from medical insurance claims and the number of new confirmed COVID-19 cases per 100,000 population (daily) for CA and FL from the COVIDcast API. We process as before, with the modification that we use `sync = locf` in `epix_merge()` so that the last version of each observation can be carried forward to extrapolate unavailable versions for the less up-to-date input archive.

```{r grab-epi-data}
theme_set(theme_bw())
#%% Remove below covidcast code and library(covidcast) 
# y <- covidcast_signals(
#   c("doctor-visits", "jhu-csse"),
#   c("smoothed_adj_cli", "confirmed_7dav_incidence_prop"),
#   start_day = "2020-06-01", 
#   end_day = "2021-12-01",
#   issues = c("2020-06-01", "2021-12-01"),
#   geo_type = "state", 
#   geo_values = c("ca", "fl")) 
# saveRDS(y, "/inst/extdata/ca_fl_covidcast_signals.rds")
y <- readRDS(
  system.file("extdata", "ca_fl_covidcast_signals.rds", package = "epipredict", mustWork = TRUE)
)
 
y1 <- y[[1]] %>% 
  select(geo_value, time_value, version = issue, percent_cli = value) %>%
  as_epi_archive()

x <- epix_merge(
  y1, y[[2]] %>% 
    select(geo_value, time_value, version = issue, case_rate = value) %>%
    as_epi_archive(), sync = "locf")
```

After obtaining the latest snapshot of the data, we produce forecasts on that data using the default engine of simple linear regression and compare to a random forest (as were introduced in the Getting started with epipredict vignette). #%% Add link to getting started vignette once html file is there!

Note that all of the warnings about `forecast_date` being less than the most recent update date of the data have been suppressed to avoid cluttering the output.

```{r make-arx-kweek, warning = FALSE}
# Latest snapshot of data, and forecast dates
x_latest <- epix_as_of(x, max_version = max(x$versions_end)) 
fc_time_values <- seq(as.Date("2020-08-01"), as.Date("2021-12-01"), 
                      by = "1 month")

k_week_ahead <- function(ahead = 7, engine_type = "linear_reg") {
  if(engine_type == "linear_reg"){
    x_latest %>%
      epi_slide(function(x, ...) 
        arx_forecaster(x, outcome = "case_rate", 
                       predictors = c("case_rate", "percent_cli"),  
                       args_list = arx_args_list(ahead = ahead))$predictions %>% 
          select(-c(geo_value, time_value)),
        n = 120, ref_time_values = fc_time_values, new_col_name = "fc") %>% 
      mutate(engine_type = "linear_reg")
  } else if (engine_type == "random_forest"){
    x_latest %>%
      epi_slide(function(x, ...) 
        arx_forecaster(x, outcome = "case_rate", 
                       predictors = c("case_rate", "percent_cli"),
                       rand_forest(mode = "regression"), 
                       args_list = arx_args_list(ahead = ahead))$predictions %>% 
          select(-c(geo_value, time_value)),
        n = 120, ref_time_values = fc_time_values, new_col_name = "fc") %>% 
      mutate(engine_type = "random_forest")
  } 
}

# Generate the forecasts, and bind them together
fc <- bind_rows(
  map_dfr(c(7,14,21,28), ~ k_week_ahead(.x, engine_type = "linear_reg")),
  map_dfr(c(7,14,21,28), ~ k_week_ahead(.x, engine_type = "random_forest"))
  ) %>% 
  mutate(
    .pred_distn = nested_quantiles(fc_.pred_distn) # "nested" list-col
  ) %>% unnest(.pred_distn) %>% 
  tidyr::spread(tau, q) 
```

Here, `arx_forecaster()` does all the heavy lifting. It creates leads of the target (respecting time stamps and locations) along with lags of the features (here, the response and doctors visits), estimates a forecasting model using the specified engine, creates predictions, and non-parametric confidence bands. All of these are tunable parameters.

Now we plot them on top of the latest case rates to see how the predictions compare.

```{r plot-arx, message = FALSE, warning = FALSE, fig.width = 9, fig.height = 6}
ggplot(fc, aes(x = fc_target_date, group = time_value, fill = engine_type)) + 
  geom_line(data = x_latest, aes(x = time_value, y = case_rate),
            inherit.aes = FALSE, color = "gray50") +
  geom_ribbon(aes(ymin = `0.05`, ymax = `0.95`), alpha = 0.4) +
  geom_line(aes(y = fc_.pred)) + geom_point(aes(y = fc_.pred), size = 0.5) +
  geom_vline(aes(xintercept = time_value), linetype = 2, alpha = 0.5) +
  facet_grid(vars(geo_value), vars(engine_type), scales = "free") +
  scale_x_date(minor_breaks = "month", date_labels = "%b %y") +
  labs(x = "Date", y = "Reported COVID-19 case rates") +
  theme(legend.position = "none")
```

Simple linear regression clearly performs better than random forest in terms of accuracy of the predictions and not does not result in such in overconfident predictions (too narrow confidence bands). Though, in general, both approaches do not perform great. This is likely because we've only used two locations, and their behaviour is rather different from each other. 

### Example using case data from Canada

By leveraging the flexibility of `epiprocess`, we can apply the same techniques to data from other sources. Since some collaborators are in British Columbia, Canada, we'll do the same thing for Canada.

The [COVID-19 Canada Open Data Working Group](https://opencovid.ca/) collects daily time series data on COVID-19 cases, deaths, recoveries, testing and vaccinations at the health region and province levels. Data are collected from publicly available sources such as government datasets and news releases. Unfortunately, there is no simple versioned source, so we have created our own from the Commit history.

First, we load versioned case rates at the provincial level. After converting these to 7-day averages (due to highly variable provincial reporting mismatches), we then convert the data to an `epi_archive` object, and extract the latest version from it. Finally, we run a very similar forcasting exercise as that above, but here we compare producing the forcasts by using simple linear regression with using boosted regression trees.

```{r get-can-fc, warning = FALSE}
# source("drafts/canada-case-rates.R)
can <- readRDS(
  system.file("extdata", "can_prov_cases.rds", 
              package = "epipredict", mustWork = TRUE)
  ) %>%
  group_by(version, geo_value) %>% 
  arrange(time_value) %>% 
  mutate(cr_7dav = RcppRoll::roll_meanr(case_rate, n = 7L)) #%>%
  #filter(geo_value %in% c('Alberta', "BC"))
can <- as_epi_archive(can)
can_latest <- epix_as_of(can, max_version = max(can$DT$version))

can_k_week_ahead <- function(ahead = 7, engine_type = "linear_reg") {
  if(engine_type == "linear_reg"){
    can_latest %>%
      epi_slide(function(x, ...) 
        arx_forecaster(x, outcome = "cr_7dav", 
                       predictors = "cr_7dav",
                       args_list = arx_args_list(ahead = ahead))$predictions %>% 
          select(-c(geo_value, time_value)),
        n = 120, ref_time_values = fc_time_values, new_col_name = "fc") %>% 
      mutate(engine_type = "linear_reg")
  } else if (engine_type == "boosted_reg_trees"){
  can_latest %>% 
    epi_slide(function(x, ...) 
      arx_forecaster(x, outcome = "cr_7dav", 
                     predictors = c("cr_7dav"),
                     boost_tree(mode = "regression", trees = 20), 
                     args_list = arx_args_list(ahead = ahead))$predictions %>% 
                select(-c(geo_value, time_value)),
              n = 120, ref_time_values = fc_time_values, new_col_name = "fc") %>% 
    mutate(engine_type = "boosted_reg_trees")
}
}

can_fc <- bind_rows(
  map_dfr(c(7,14,21,28), ~ can_k_week_ahead(.x, engine_type = "linear_reg")),
  map_dfr(c(7,14,21,28), ~ can_k_week_ahead(.x, engine_type = "boosted_reg_trees"))
  ) %>% 
  mutate(
    .pred_distn = nested_quantiles(fc_.pred_distn) # "nested" list-col
  ) %>% unnest(.pred_distn) %>% 
  tidyr::spread(tau, q) 
```

The figures below shows the results for all of the provinces. 

```{r plot-can-fc-lr, message = FALSE, warning = FALSE, fig.width = 9, fig.height = 12}
ggplot(can_fc %>% filter(engine_type == "linear_reg"), 
       aes(x = fc_target_date, group = time_value)) +
  coord_cartesian(xlim = lubridate::ymd(c("2020-12-01", NA))) +
  geom_line(data = can_latest, aes(x = time_value, y = cr_7dav),
            inherit.aes = FALSE, color = "gray50") +
  geom_ribbon(aes(ymin = `0.05`, ymax = `0.95`, fill = geo_value),
              alpha = 0.4) +
  geom_line(aes(y = fc_.pred)) + geom_point(aes(y = fc_.pred), size = 0.5) +
  geom_vline(aes(xintercept = time_value), linetype = 2, alpha = 0.5) +
  facet_wrap(~geo_value, scales = "free_y", ncol = 3) +
  scale_x_date(minor_breaks = "month", date_labels = "%b %y") +
  labs(title = "Using simple linear regression", x = "Date", 
       y = "Reported COVID-19 case rates") +
  theme(legend.position = "none")  
```

```{r plot-can-fc-boost, message = FALSE, warning = FALSE, fig.width = 9, fig.height = 12}
ggplot(can_fc %>% filter(engine_type == "boosted_reg_trees"), 
       aes(x = fc_target_date, group = time_value)) +
  coord_cartesian(xlim = lubridate::ymd(c("2020-12-01", NA))) +
  geom_line(data = can_latest, aes(x = time_value, y = cr_7dav),
            inherit.aes = FALSE, color = "gray50") +
  geom_ribbon(aes(ymin = `0.05`, ymax = `0.95`, fill = geo_value),
              alpha = 0.4) +
  geom_line(aes(y = fc_.pred)) + geom_point(aes(y = fc_.pred), size = 0.5) +
  geom_vline(aes(xintercept = time_value), linetype = 2, alpha = 0.5) +
  facet_wrap(~ geo_value, scales = "free_y", ncol = 3) +
  scale_x_date(minor_breaks = "month", date_labels = "%b %y") +
  labs(title = "Using boosted regression trees", x = "Date", 
       y = "Reported COVID-19 case rates") +
  theme(legend.position = "none")  
```

Both approaches tend to produce quite volatile forecasts (point predictions) and/or are overly confident (very narrow bands), particularly when boosted regression trees were used. As this is meant to be a simple demonstration of sliding with different engines in `arx_forecaster`, we may devote another vignette to work on improving the predictive modelling using the suite of tools available in epipredict.

## Version-aware and unaware forecasting

### Example using case data from CA and FL 

We will now employ a forecaster that uses properly-versioned data (that would have been available in real-time) to forecast future COVID-19 case rates from current and past COVID-19 case rates for CA and FL. That is, we can make forecasts on the archive, `x`, and compare to forecasts on the latest data, `x_latest` using the same general set-up as above. For version-aware forecasting, note that `x` is fed into `epix_slide()`, while for version-unaware forecasting, `x_latest` is fed into `epi_slide()`. #%% update to include percent_cli after that issue is fixed?

```{r make-ar-kweek-asof}

k_week_ahead_as_of <- function(ahead = 7, as_of = TRUE) {
  if (as_of) {
    x %>% 
      epix_slide(function(x, ...) 
        arx_forecaster(x, outcome = "case_rate", 
                       predictors = "case_rate",
                       args_list = arx_args_list(ahead = ahead))$predictions %>% 
          select(-c(geo_value, time_value)),
        n = 120, ref_time_values = fc_time_values, new_col_name = "fc") %>% 
      mutate(as_of = as_of)
  } else {
    x_latest %>%
      epi_slide(function(x, ...) 
        arx_forecaster(x, outcome = "case_rate", 
                       predictors = "case_rate",
                       args_list = arx_args_list(ahead = ahead))$predictions %>%
          select(-c(geo_value, time_value)),
        n = 120, ref_time_values = fc_time_values, new_col_name = "fc") %>% 
      mutate(as_of = as_of)
  }
}

# Generate the forecasts, and bind them together
fc <- bind_rows(
  map_dfr(c(7,14,21,28), ~ k_week_ahead_as_of(.x, as_of = TRUE)),
  map_dfr(c(7,14,21,28), ~ k_week_ahead_as_of(.x, as_of = FALSE))
  ) %>% 
  mutate(
    .pred_distn = nested_quantiles(fc_.pred_distn) # "nested" list-col
    ) %>% unnest(.pred_distn) %>% 
  tidyr::spread(tau, q) 

```

Now we plot the results on top of the latest case rates.

```{r plot-ar-asof, message = FALSE, warning = FALSE, fig.width = 9, fig.height = 6}
ggplot(fc, aes(x = fc_target_date, group = time_value, fill = as_of)) +
  geom_line(data = x_latest, aes(x = time_value, y = case_rate),
            inherit.aes = FALSE, color = "gray50") +
  geom_ribbon(aes(ymin = `0.05`, ymax = `0.95`), alpha = 0.4) +
  geom_line(aes(y = fc_.pred)) + geom_point(aes(y = fc_.pred), size = 0.5) +
  geom_vline(aes(xintercept = time_value), linetype = 2, alpha = 0.5) +
  facet_grid(vars(geo_value), vars(as_of), scales = "free") +
  scale_x_date(minor_breaks = "month", date_labels = "%b %y") +
  labs(x = "Date", y = "Reported COVID-19 case rates") +
  theme(legend.position = "none")
```

Again, we observe that the results are rather abysmal, but that's again likely because we've only used two locations, which exhibit quite different behaviour.

We shall leave it to the reader to try the above version aware and unaware forecasting exercise on the Canadian case rate data. The above code for the American state data should be readily adaptable for this purpose.  
